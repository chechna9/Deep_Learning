{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1wLL0PVm8_bCwFsVUMSfqdPaQ1eFSfrwj","timestamp":1637764515952},{"file_id":"1NpCysVZ0FfyUMdwTPHdk2E3XWiJ45wPR","timestamp":1570932024859}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tG3FpzjPt0xr"},"source":["# Auto-encodeurs débruiteurs avec Keras"]},{"cell_type":"markdown","metadata":{"id":"dwA9xMdHt4sb"},"source":["## Vérification de l'utilisation de GPU\n","\n","Allez dans le menu `Exécution > Modifier le type d'execution` et vérifiez que l'on est bien en Python 3 et que l'accélérateur matériel est configuré sur « GPU »."]},{"cell_type":"code","metadata":{"id":"JeXU4lw0TGQq"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NgbfFbJt_V5"},"source":["## Import de TensorFlow et des autres librairies nécessaires"]},{"cell_type":"code","metadata":{"id":"j5OnIl-BHSfx"},"source":["import matplotlib.pyplot as plt\n","import numpy\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l3BhjGTdLz_e"},"source":["## Chargement de MNIST\n","\n","Nous allons utiliser un prétraîtement légèrement différent des autres fois : étant donné que nous voulons pouvoir prédire les valeurs données en entrée en sortie (principe de l'auto-encodage), nous allons simplement projeter ces valeurs dans $[0, 1]$ au lieu de $[0, 255]$. Notez qu'habituellement nous ne faisons pas ça : nous normalisons en centrant sur zéro et en divisant par l'écart-type."]},{"cell_type":"code","metadata":{"id":"hzmZuz_HIVO0"},"source":["(X_train, _), (X_test, y_test) = keras.datasets.mnist.load_data()\n","nb_classes = 10\n","input_dim = 28 * 28\n","X_train = X_train.reshape(-1, input_dim).astype('float32')\n","X_test = X_test.reshape(-1, input_dim).astype('float32')\n","\n","# On utilise cette normalisation pour garder les pixel à 0 où ils sont\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hsR_fKX3dOnF"},"source":["## Application d'un bruit  gaussien"]},{"cell_type":"code","metadata":{"id":"VRKjObLvdH-Z"},"source":["noise_factor = 0.3\n","X_train_noisy = X_train + numpy.random.normal(0, noise_factor, X_train.shape) \n","X_test_noisy = X_test + numpy.random.normal(0, noise_factor, X_test.shape)\n","\n","# On clip les valeurs pour éviter les pixels plus blanc que blanc (ou plus noir\n","# que noir) \n","numpy.clip(X_train_noisy, 0, 1, out=X_train_noisy)\n","numpy.clip(X_test_noisy, 0, 1, out=X_test_noisy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KgKpN7EsdtVc"},"source":["n = 10\n","f, ax = plt.subplots(1, n, figsize=(n * 1.4, 2))\n","for i in range(n):\n","    ax[i].imshow(X_test_noisy[i].reshape(28, 28), cmap=\"gray_r\")\n","    ax[i].set_title(y_test[i])\n","    ax[i].axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hi0dZwTvL74R"},"source":["## Création de l'autoencodeur débruiteur\n","\n"]},{"cell_type":"code","metadata":{"id":"jEktY3zWXGBr"},"source":["# Votre code ici\n","encoding_dim = 4\n","\n","autoencoder = keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FpfqqlI-Xh5N"},"source":["## Apprentissage\n","\n","*Écrivez la ligne correspondant à l'apprentissage de votre autoencodeur :*\n","\n","- *50 itérations devraient suffire*\n","- *Utilisez un batch de 256*"]},{"cell_type":"code","metadata":{"id":"e457ISDiYnzn"},"source":["# Votre code ici"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UWbYZXb6YwhM"},"source":["## Base de Test\n","\n","Autoencodez les images de test et stockez les images obtenues dans la variable `X_test_noisy_pred`"]},{"cell_type":"code","metadata":{"id":"gO0E47nRZND-"},"source":["# Votre code ici\n","X_test_noisy_pred = X_test_noisy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T7KLWxZpZZWp"},"source":["## Affichage visuel de la performance"]},{"cell_type":"code","metadata":{"id":"elXKC4kxIexp"},"source":["n = 10\n","_, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n","for i, (ax_top, ax_bottom) in enumerate(ax.T):\n","    # L'original en haut\n","    ax_top.imshow(X_test_noisy[i].reshape(28, 28), cmap=\"gray_r\")\n","    ax_top.set_title(str(y_test[i]))\n","    ax_top.axis(\"off\")\n","\n","    # La reconstruction en bas\n","    ax_bottom.imshow(X_test_noisy_pred[i].reshape(28, 28), cmap=\"gray_r\")\n","    ax_bottom.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uhlicf7oZ3wl"},"source":["## Essayez avec plus de neurones\n","\n","Que se passe-t-il ?"]},{"cell_type":"markdown","metadata":{"id":"7zluxB_On8ca"},"source":["## Utilisation des réseaux convolutifs\n","\n","Pour cela il faut remettre chaque image sous forme 28x28x1. Les CNNs ont besoin de cette 3ème dimension de tenseur (il pourrait y avoir plus de canaux que le niveau de gris : il y en a 3 pour les images en couleur et plus encore dans les couches intermédiaires d'un réseau convolutif où le nombre de canaux en entrée d'une couche sera le nombre de kernels de la couche précédente)."]},{"cell_type":"code","metadata":{"id":"-LcXRU-ooX9c"},"source":["X_train = X_train.reshape(-1, 28, 28, 1)\n","X_test = X_test.reshape(-1, 28, 28, 1)\n","X_train_noisy = X_train_noisy.reshape(-1, 28, 28, 1)\n","X_test_noisy = X_test_noisy.reshape(-1, 28, 28, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHLn3Y0bxP1g"},"source":["## Création du modèle\n","\n","On utilisera des séquences de [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/), [`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/) avec des kernel de respectivement 3 × 3 et 2 × 2 pour la partie encodeur. Dans ces deux layers, il faudra utiliser l'option `padding=\"same\"` afin d'éviter les effets de bord (l'image étant déjà assez petite comme ça).\n","\n","Pour la partie décodeur, on utilisera des [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/) de même nature suivis par des [`UpSampling2D`](https://keras.io/api/layers/reshaping_layers/up_sampling2d/) (de taille 2 × 2) qui correspondent à l'opération inverse de [`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/).\n","\n","N'hésitez pas à abuser de `model.summary()` pour vous y retrouver. L'objectif étant de retrouver une image 28 × 28 × 1 à la sortie du dernier [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/). En effet, finir par un [`UpSampling2D`](https://keras.io/api/layers/reshaping_layers/up_sampling2d/) serait une mauvaise idée.\n","\n","Le réseau va être profond, on utilisera des fonctions d'activation ReLU, sauf pour la dernière où on utilisera une sigmoïde."]},{"cell_type":"code","metadata":{"id":"ySGG5N5CzJLd"},"source":["# Votre code ici\n","autoencoder = keras.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bz2V4Enzz8CX"},"source":["## Apprentissage\n","\n","*Écrivez la ligne correspondant à l'apprentissage de votre autoencodeur :*\n","\n","- *100 itérations devraient suffire*\n","- *Utilisez un batch de 256*"]},{"cell_type":"code","metadata":{"id":"3YeaMCqyz8Cw"},"source":["# Votre code ici"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDoOAPbOzaMW"},"source":["## Affichage des performances"]},{"cell_type":"code","metadata":{"id":"j1zvzPqQtqgy"},"source":["X_test_noisy_pred = autoencoder.predict(X_test_noisy).reshape(-1, 28, 28)\n","\n","n = 10\n","\n","random_indexes = numpy.random.choice(X_test.shape[0],\n","                                     replace=False,\n","                                     size=n)\n","\n","_, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n","for (ax_top, ax_bottom), random_index in zip(ax.T, random_indexes):\n","    # L'image originale en haut\n","    ax_top.set_title(str(y_test[random_index]))\n","    ax_top.imshow(X_test_noisy[random_index].reshape(28, 28), cmap=\"gray_r\")\n","    ax_top.axis(\"off\")\n","\n","    # L'image reconstruite en bas\n","    ax_bottom.imshow(X_test_noisy_pred[random_index], cmap=\"gray_r\")\n","    ax_bottom.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AiOFCmhbudGD"},"source":["## Sur des images non-bruitées"]},{"cell_type":"code","metadata":{"id":"w1FGetiyMdxh"},"source":["X_test_pred = autoencoder.predict(X_test).reshape(-1, 28, 28)\n","\n","n = 10\n","\n","random_indexes = numpy.random.choice(X_test.shape[0],\n","                                     replace=False,\n","                                     size=n)\n","\n","_, ax = plt.subplots(2, n, figsize=(n * 1.4, 4))\n","for (ax_top, ax_bottom), random_index in zip(ax.T, random_indexes):\n","    # L'image originale en haut\n","    ax_top.set_title(str(y_test[random_index]))\n","    ax_top.imshow(X_test[random_index].reshape(28, 28), cmap=\"gray_r\")\n","    ax_top.axis(\"off\")\n","\n","    # L'image reconstruite en bas\n","    ax_bottom.imshow(X_test_pred[random_index], cmap=\"gray_r\")\n","    ax_bottom.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]}]}